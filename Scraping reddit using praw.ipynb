{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping comments from Reddit using PRAW "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we will demonstrate how Python's [praw](https://praw.readthedocs.io/en/latest/) library can be used to scrape comments from threads within Reddit subreddits via the Reddit API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the Reddit API "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to access the API you need a client ID and client secret. To obtain these follow the instructions under **First Steps** [here](https://github.com/reddit-archive/reddit/wiki/OAuth2-Quick-Start-Example). Before following the instructions you will first need to create a Reddit account and sign into this account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have obtained the required credentials, it is best to store them in a .json file in order to keep them secure. The file structure is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "{\"username\":YourUsername, \n",
    " \"password\": YourPassword, \n",
    " \"client_id\":YourClientID, \n",
    " \"client_secret\":YourClientSecret}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of this tutorial we assume that this information is stored within a file named `reddit_credentials.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Reddit instance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the API, we create an authorised `reddit` instance by passing credentials (stored in `reddit_credentials.json`) to praw's Reddit class. As your credentials are stored in a `.json` file, once the file is loaded it can be treated as a python `dict`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "import praw\n",
    "import json \n",
    "\n",
    "\n",
    "with open('reddit_credentials.json') as fin:\n",
    "    creds = json.load(fin)\n",
    "    \n",
    "reddit = praw.Reddit(user_agent='Comment Extraction (by /u/{0})'.format(creds['username']),\n",
    "                     client_id=creds['client_id'], client_secret=creds['client_secret'],\n",
    "                     username=creds['username'], password=creds['password'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing a Subreddit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a `subreddit` instance by passing the name of the subreddit to our `reddit` instance. For this tutorial we will use the AskReddit subreddit: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "subreddit = reddit.subreddit('AskReddit')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining threads within a subreddit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our end goal is to scrape comments from threads within a subreddit. Our `subreddit` instance can be used to obtain `submissions` (ie. threads) within the subreddit. There are various orders in which submissions can be accessed, described in the [praw documentation](https://praw.readthedocs.io/en/latest/getting_started/quick_start.html#obtain-submission-instances-from-a-subreddit). Here we will at those which are `hot`, or currently begin highly commented. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by looping through the 10 'rising' threads in our subreddit and printing the title:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "for submission in subreddit.rising(limit=10):\n",
    "    print(submission.title)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The title is just one bit of metadata realting to each thread that can be obtained. As we want as much metadata as possible, we can create a funuction to obtain all metadata needed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def get_metadata(submission):\n",
    "\n",
    "    thread={}\n",
    "    thread[\"title\"]=submission.title\n",
    "    thread[\"score\"]=submission.score\n",
    "    thread[\"id\"]=submission.id\n",
    "    thread[\"url\"]=submission.url\n",
    "    thread[\"comms_num\"]=submission.num_comments\n",
    "    thread[\"created\"]=submission.created\n",
    "    thread[\"body\"]=submission.selftext\n",
    "\n",
    "    return thread\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our function will return a `dict` containing metadata about each thread. \n",
    "\n",
    "We can now loop through the 10 rising threads, obtain the metadata for each one and save the results to a file named `askreddit.json`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "with open('askreddit.json', 'w') as fout:\n",
    "    for submission in subreddit.rising(limit=10):\n",
    "    \n",
    "        thread = get_metadata(submission)\n",
    "        json.dump(thread,fout)\n",
    "        fout.write('\\n')\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining comments from a thread "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now able to loop through `submissions` (threads) within a subreddit and obtain metadata about each one. \n",
    "\n",
    "In order to obtain the comments from each `submission` we can use the `comments` attribute. As the structure of the comments in a subreddit thread is tree-like, where a top-level comment can be replied to many times, and each reply can be replied to, we need to traverse through the \"comment tree\" to obtain all comments.\n",
    "\n",
    "Traversing through the tree is easy thanks to the `CommentForest` object in praw. For in-depth details see the [example](https://praw.readthedocs.io/en/latest/tutorials/comments.html#extracting-comments) in praw's documantation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the structure of a thread within AskReddit (or any other subreddit) you see that in order to view all comments you must click '1 more commment', '21 more comments' etc.\n",
    "\n",
    "An important point to note is that, to obtain *all* comments in a thread, we need to be performing a similar action to this. In praw, this can be acieved using the `replace_more` method, which is part of `CommentForest`. \n",
    "\n",
    "Specifically, to obtain all coments we can call the `comments` attribute on each `submission` with the `replace_more` method and a limit of `None`. This only needs to be done once, after which a list of all comments can be looped over and comment data can be obtained:   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "def get_comments(submission):\n",
    "\n",
    "    comments=[]\n",
    "\n",
    "    submission.comments.replace_more(limit=None)\n",
    "    for comment in submission.comments.list():\n",
    "        data={}\n",
    "        data['body']=comment.body\n",
    "        data['id']=comment.fullname\n",
    "\n",
    "        try:\n",
    "            data['author']=comment.author.name\n",
    "\n",
    "        except AttributeError:\n",
    "            data['author']=comment.author\n",
    "\n",
    "        data['time']=comment.created_utc\n",
    "        data['parent']=comment.parent_id\n",
    "\n",
    "        comments.append(data)\n",
    "\n",
    "    return comments\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it together "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the above function `get_comments` from within the `get_metadata` function, we can now obtain data for all comments in a subreddit thread for all threads in a subreddit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "import json \n",
    "\n",
    "def get_comments(submission):\n",
    "\n",
    "    comments=[]\n",
    "\n",
    "    submission.comments.replace_more(limit=None)\n",
    "    for comment in submission.comments.list():\n",
    "        data={}\n",
    "        data['body']=comment.body\n",
    "        data['id']=comment.fullname\n",
    "\n",
    "        try:\n",
    "            data['author']=comment.author.name\n",
    "\n",
    "        except AttributeError:\n",
    "            data['author']=comment.author\n",
    "\n",
    "        data['time']=comment.created_utc\n",
    "        data['parent']=comment.parent_id\n",
    "\n",
    "        comments.append(data)\n",
    "\n",
    "    return comments\n",
    "\n",
    "\n",
    "def get_metadata(submission):\n",
    "\n",
    "    thread={}\n",
    "    thread[\"title\"]=submission.title\n",
    "    thread[\"score\"]=submission.score\n",
    "    thread[\"id\"]=submission.id\n",
    "    thread[\"url\"]=submission.url\n",
    "    thread[\"comms_num\"]=submission.num_comments\n",
    "    thread[\"created\"]=submission.created\n",
    "    thread[\"body\"]=submission.selftext\n",
    "    \n",
    "    thread['posts']= get_comments(submission)\n",
    "\n",
    "    return thread\n",
    "\n",
    "\n",
    "\n",
    "with open('reddit_credentials.json') as fin:\n",
    "    \n",
    "    creds = json.load(fin)\n",
    "    \n",
    "\n",
    "reddit = praw.Reddit(user_agent='Comment Extraction (by /u/{0})'.format(creds['username']),\n",
    "                     client_id=creds['client_id'], client_secret=creds['client_secret'],\n",
    "                     username=creds['username'], password=creds['password'])\n",
    "\n",
    "\n",
    "subreddit = reddit.subreddit('AskReddit')\n",
    "\n",
    "with open('askreddit.json', 'w') as fout:\n",
    "    \n",
    "    for submission in subreddit.rising(limit=10):\n",
    "    \n",
    "        thread = get_metadata(submission)\n",
    "        json.dump(thread,fout)\n",
    "        fout.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally.... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to speed up this code, try the tutorial [Introduction to threading in Python](Introduction to threading in Python.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
